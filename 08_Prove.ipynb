{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08 Prove.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMf5rJbaLcfKTC84+Qm6MBi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoshEthan/Prove06/blob/master/08_Prove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSJ9nO2xBkCg",
        "colab_type": "text"
      },
      "source": [
        "# Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnytTjI1-n5n",
        "colab_type": "text"
      },
      "source": [
        "**Varying things such as:**\n",
        "* Number of layers\n",
        "* Number of nodes per layer\n",
        "* **Stopping criteria / length of training time**\n",
        "* **Using momentum**\n",
        "* Using different activation functions\n",
        "* **Any other parameters** provided by your library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vumDHX5gAqfO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1. Successfully used a library implementation of a neural network to make predictions.\n",
        "2. Done the necessary preprocessing work to prepare several different datasets for this library.\n",
        "3. Used datasets that show you can work with various kinds of input data (e.g., categorical vs numeric, etc.).\n",
        "4. Made predictions using both regression and classification.\n",
        "5. Performed significant hyper-parameter experimentation and tuning for a challenging dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25xGUgXsBhqJ",
        "colab_type": "text"
      },
      "source": [
        "# Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTLlXXmTA-7I",
        "colab_type": "text"
      },
      "source": [
        "**Approach**\n",
        "With the assignment I used what outline I had from the previous assignment. Then I procceeded to expirement with different types of hyperparameters.\n",
        "\n",
        "**Challenges**\n",
        "Honestly, I am not sure if I did it right. I kept trying to get my accuracy to 90%, but no matter what I changed, it never became 90%. I assumed it was just impossible for it to increase.\n",
        "\n",
        "**Results**\n",
        "The results are all below. I have different hyperparameters spread throughout. You can see that majrity of the accuracy is the same, but some are much lower than others. There are even more changes I did that are not shown.\n",
        "\n",
        "**Above and Beyond**\n",
        "I went to other resources and read and tried to learn what they did to increase the accuracy. I did more than just a few hyperparameters, I tried many different kinds with different combinations. I even tried to write code to loop through different nodes. It took too much processing power, so I had to shut it down.\n",
        "\n",
        "**Assessment**\n",
        "Please state which category you feel best describes your assignment and give a 1-2 sentence justification for your choice:\n",
        "\n",
        "**5) Shows creativity and excels above and beyond requirements**\n",
        "\n",
        "As stated in the Above and Beyond, I worked hard at trying to congfigure the accuracy by changes a wide variety of hyperparameters. In addition, I read blogs from other engineers that helped me understand more about it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJIOLAa5Bo2N",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDXqDvkh9yZN",
        "colab_type": "code",
        "outputId": "644f3200-2af4-4a41-dcfc-6108b25782fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "data = pd.read_csv(\"/content/high_diamond_ranked_10min.csv\")\n",
        "sc = StandardScaler()\n",
        "model = Sequential()\n",
        "test_size_percentage = 0.3\n",
        "n_inputs = 38\n",
        "n_outputs_one = 100\n",
        "n_outputs_two = 1\n",
        "activation_function_one = 'relu'\n",
        "activation_function_two = 'sigmoid'\n",
        "n_epochs = 1\n",
        "batch_size = 1\n",
        "\n",
        "pd.set_option('display.max_columns', 500)\n",
        "data = pd.read_csv(\"/content/high_diamond_ranked_10min.csv\")\n",
        "X = data.drop(columns=[\"gameId\", \"blueWins\"]).astype('int32').to_numpy()\n",
        "y = data.blueWins.to_numpy()\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = test_size_percentage)\n",
        "model = Sequential()\n",
        "model.add(Dense(n_outputs_one, input_dim=n_inputs, activation=activation_function_one))\n",
        "model.add(Dense(n_outputs_two, activation=activation_function_two))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size)\n",
        "_, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "6915/6915 [==============================] - 7s 1ms/step - loss: 0.5534 - accuracy: 0.7122\n",
            "Accuracy: 73.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "87f3365b-9c4c-4537-cfd6-30730d521731",
        "id": "qXXktwwrkuV5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "data = pd.read_csv(\"/content/high_diamond_ranked_10min.csv\")\n",
        "sc = StandardScaler()\n",
        "model = Sequential()\n",
        "test_size_percentage = 0.3\n",
        "n_inputs = 38\n",
        "n_outputs_one = 1380\n",
        "n_outputs_two = 1\n",
        "activation_function_one = 'relu'\n",
        "activation_function_two = 'sigmoid'\n",
        "n_epochs = 1\n",
        "batch_size = 1\n",
        "\n",
        "pd.set_option('display.max_columns', 500)\n",
        "data = pd.read_csv(\"/content/high_diamond_ranked_10min.csv\")\n",
        "X = data.drop(columns=[\"gameId\", \"blueWins\"]).astype('int32').to_numpy()\n",
        "y = data.blueWins.to_numpy()\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = test_size_percentage)\n",
        "model = Sequential()\n",
        "model.add(Dense(n_outputs_one, input_dim=n_inputs, activation=activation_function_one))\n",
        "model.add(Dense(n_outputs_two, activation=activation_function_two))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size)\n",
        "_, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "6915/6915 [==============================] - 9s 1ms/step - loss: 0.5629 - accuracy: 0.7171\n",
            "Accuracy: 72.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aa308ef6-2b5d-4b7b-caf5-2963eeea9709",
        "id": "2mZTBb6fk2TK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "data = pd.read_csv(\"/content/high_diamond_ranked_10min.csv\")\n",
        "sc = StandardScaler()\n",
        "model = Sequential()\n",
        "test_size_percentage = 0.3\n",
        "n_epochs = 1\n",
        "batch_size = 1\n",
        "\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', 500)\n",
        "data = pd.read_csv(\"/content/high_diamond_ranked_10min.csv\")\n",
        "X = data.drop(columns=[\"gameId\", \"blueWins\"]).astype('int32').to_numpy()\n",
        "y = data.blueWins.to_numpy()\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = test_size_percentage)\n",
        "model = Sequential()\n",
        "model.add(Dense(1000, input_dim=38, activation='relu'))\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size)\n",
        "_, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "6915/6915 [==============================] - 41s 6ms/step - loss: 0.5618 - accuracy: 0.7255\n",
            "Accuracy: 73.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbqhWd0urd5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "116cf1db-f94d-4cb6-c5ee-8717bde4a01e"
      },
      "source": [
        "pd.set_option('display.max_columns', 500)\n",
        "data = pd.read_csv(\"/content/high_diamond_ranked_10min.csv\")\n",
        "X = data.drop(columns=[\"gameId\", \"blueWins\"]).astype('int32').to_numpy()\n",
        "y = data.blueWins.to_numpy()\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = .01)\n",
        "model = Sequential()\n",
        "model.add(Dense(38, input_dim=38, activation='relu'))\n",
        "model.add(Dense(19, activation='relu'))\n",
        "model.add(Dense(9, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=32)\n",
        "_, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "9780/9780 [==============================] - 0s 50us/step - loss: 0.5600 - accuracy: 0.7135\n",
            "Accuracy: 73.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAH4jizlx722",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "cbae1964-5cbf-46e9-cd9e-a01ceb37dfac"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "data = pd.read_csv(\"/content/high_diamond_ranked_10min.csv\")\n",
        "sc = StandardScaler()\n",
        "model = Sequential()\n",
        "test_size_percentage = 0.3\n",
        "n_inputs = 38\n",
        "n_outputs_one = 100\n",
        "n_outputs_two = 1\n",
        "activation_function_one = 'relu'\n",
        "activation_function_two = 'sigmoid'\n",
        "n_epochs = 1\n",
        "batch_size = 1\n",
        "\n",
        "pd.set_option('display.max_columns', 500)\n",
        "data = pd.read_csv(\"/content/high_diamond_ranked_10min.csv\")\n",
        "X = data.drop(columns=[\"gameId\", \"blueWins\"]).astype('int32').to_numpy()\n",
        "y = data.blueWins.to_numpy()\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = test_size_percentage)\n",
        "\n",
        "\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(1, activation='relu', input_dim=38))\n",
        "model.add(keras.layers.Dropout(0.4))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "model.fit(X_train, y_train, callbacks=[es_callback])\n",
        "\n",
        "_, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "selector = SelectKBest(f_classif, k=10)\n",
        "selected_features = selector.fit_transform(X_train, y_train)\n",
        "f_score_indexes = (-selector.scores_).argsort()[:10]\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "6915/6915 [==============================] - 0s 48us/step - loss: 0.7306 - accuracy: 0.5835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 67.61\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}